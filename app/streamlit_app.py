import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.metrics import mean_squared_error, mean_absolute_error
import matplotlib.pyplot as plt
import japanize_matplotlib  # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®ã‚µãƒãƒ¼ãƒˆ
from datetime import datetime
import os

# ãƒšãƒ¼ã‚¸ã®è¨­å®š
st.set_page_config(
    page_title="SageMaker Canvasæ™‚ç³»åˆ—ãƒ¢ãƒ‡ãƒ«åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜
st.title("SageMaker Canvasæ™‚ç³»åˆ—ãƒ¢ãƒ‡ãƒ«åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
st.markdown("Amazon SageMaker Canvasã§ä½œæˆã—ãŸæ™‚ç³»åˆ—ãƒ¢ãƒ‡ãƒ«ã®åˆ†æçµæœã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")

# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿é–¢æ•°
@st.cache_data
def load_data():
    # ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ã‚’æŒ‡å®šï¼ˆStreamlit Cloudã§ã‚‚å‹•ä½œã™ã‚‹ã‚ˆã†ã«çµ¶å¯¾ãƒ‘ã‚¹ã‚’ä½¿ç”¨ï¼‰
    import os
    
    # ã‚¢ãƒ—ãƒªã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—
    root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ã‚’çµ¶å¯¾ãƒ‘ã‚¹ã§æŒ‡å®š
    train_path = os.path.join(root_dir, "data", "train", "SKU_rev_train.csv")
    test_path = os.path.join(root_dir, "data", "test", "SKUéœ€è¦äºˆæ¸¬_test.csv")
    result_path = os.path.join(root_dir, "data", "result", "result_summary.csv")
    
    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    train_df = pd.read_csv(train_path)
    test_df = pd.read_csv(test_path)
    result_df = pd.read_csv(result_path)
    
    # æ—¥ä»˜åˆ—ã‚’æ—¥ä»˜å‹ã«å¤‰æ›
    train_df['Date'] = pd.to_datetime(train_df['Date'], format='%Y/%m/%d')
    test_df['Date'] = pd.to_datetime(test_df['Date'], format='%Y/%m/%d')
    result_df['Date'] = pd.to_datetime(result_df['Date'])
    
    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
    df = pd.concat([train_df, test_df], ignore_index=True)
    
    # äºˆæ¸¬çµæœã‚’çµåˆ
    # result_dfã«ã¯äºˆæ¸¬å€¤ï¼ˆp10, p50, p90, meanï¼‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹
    # p50ï¼ˆä¸­å¤®å€¤ï¼‰ã‚’äºˆæ¸¬å€¤ã¨ã—ã¦ä½¿ç”¨
    df_with_prediction = df.copy()
    
    # äºˆæ¸¬çµæœã‚’ãƒãƒ¼ã‚¸
    prediction_data = result_df[['Item_name', 'Date', 'p50']].rename(columns={'p50': 'Prediction'})
    df_with_prediction = pd.merge(
        df_with_prediction, 
        prediction_data, 
        on=['Item_name', 'Date'], 
        how='left'
    )
    
    return df_with_prediction

# æŒ‡æ¨™è¨ˆç®—é–¢æ•°
def calculate_metrics(actual, predicted):
    # NaNã‚’é™¤å¤–
    mask = ~np.isnan(actual) & ~np.isnan(predicted)
    actual = actual[mask]
    predicted = predicted[mask]
    
    rmse = np.sqrt(mean_squared_error(actual, predicted))
    mae = mean_absolute_error(actual, predicted)
    
    # MAPEã®è¨ˆç®—ï¼ˆã‚¼ãƒ­é™¤ç®—ã‚’å›é¿ï¼‰
    mask = actual != 0  # ã‚¼ãƒ­ã§ãªã„å€¤ã®ãƒã‚¹ã‚¯
    if np.any(mask):
        # ã‚¼ãƒ­ã§ãªã„å€¤ã®ã¿ã§MAPEã‚’è¨ˆç®—
        mape = np.mean(np.abs((actual[mask] - predicted[mask]) / actual[mask])) * 100
    else:
        mape = np.nan  # ã™ã¹ã¦ã‚¼ãƒ­ã®å ´åˆã¯NaNã‚’è¿”ã™
    
    # éå‰°åœ¨åº«ç‡ï¼ˆäºˆæ¸¬>å®Ÿç¸¾ã®å‰²åˆï¼‰
    overstock_rate = np.mean(predicted > actual) * 100
    
    # æ¬ å“ç‡ï¼ˆäºˆæ¸¬<å®Ÿç¸¾ã®å‰²åˆï¼‰
    stockout_rate = np.mean(predicted < actual) * 100
    
    return {
        'RMSE': rmse,
        'MAE': mae,
        'MAPE': mape,
        'Overstock Rate': overstock_rate,
        'Stockout Rate': stockout_rate
    }

# ç‰¹å¾´é‡é‡è¦åº¦ã®è¨ˆç®—
def get_feature_importance(df, sku_id):
    # é¸æŠã—ãŸå•†å“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    sku_data = df[df['Item_name'] == sku_id].copy()
    
    # ç‰¹å¾´é‡ã®åˆ—åã‚’å–å¾—
    feature_cols = [
        'Price', 'coupon_rate', 'holiday', 'tempreture',
        'precipitation', 'Sales_lag_1', 'Sales_lag_7', 'CPI',
        'Closed_flag', 'market_flag'
    ]
    
    # ç‰¹å¾´é‡ã®é‡è¦åº¦ã‚’è¨ˆç®—ï¼ˆç›¸é–¢ä¿‚æ•°ã®çµ¶å¯¾å€¤ã‚’ä½¿ç”¨ï¼‰
    importances = []
    for col in feature_cols:
        if col in sku_data.columns:
            # NaNã‚’é™¤å¤–ã—ã¦ç›¸é–¢ä¿‚æ•°ã‚’è¨ˆç®—
            corr = sku_data[['Sales', col]].dropna().corr().iloc[0, 1]
            importances.append(abs(corr))
        else:
            importances.append(0)
    
    # ç‰¹å¾´é‡é‡è¦åº¦ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
    importance_df = pd.DataFrame({
        'Feature': feature_cols,
        'Importance': importances
    })
    
    # é‡è¦åº¦ã§ã‚½ãƒ¼ãƒˆ
    importance_df = importance_df.sort_values('Importance', ascending=False)
    
    # é‡è¦åº¦ã‚’0-1ã®ç¯„å›²ã«æ­£è¦åŒ–
    if importance_df['Importance'].max() > 0:
        importance_df['Importance'] = importance_df['Importance'] / importance_df['Importance'].max()
    
    return importance_df

# ç•°å¸¸æ¤œå‡ºé–¢æ•°
def detect_anomalies(actual, predicted, threshold=2):
    # NaNã‚’é™¤å¤–
    mask = ~np.isnan(actual) & ~np.isnan(predicted)
    actual_clean = actual[mask]
    predicted_clean = predicted[mask]
    
    residuals = actual_clean - predicted_clean
    mean_residual = np.mean(residuals)
    std_residual = np.std(residuals)
    
    # æ¨™æº–åå·®ã®é–¾å€¤ã‚’è¶…ãˆã‚‹èª¤å·®ã‚’æŒã¤ãƒã‚¤ãƒ³ãƒˆã‚’ç‰¹å®š
    anomalies = np.abs(residuals - mean_residual) > threshold * std_residual
    
    # å…ƒã®é…åˆ—ã¨åŒã˜ã‚µã‚¤ã‚ºã®çµæœé…åˆ—ã‚’ä½œæˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯Falseï¼‰
    full_anomalies = np.zeros(len(actual), dtype=bool)
    
    # ãƒã‚¹ã‚¯ã•ã‚ŒãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å¯¾å¿œã™ã‚‹ä½ç½®ã«ç•°å¸¸å€¤ãƒ•ãƒ©ã‚°ã‚’è¨­å®š
    full_anomalies[mask] = anomalies
    
    return full_anomalies

# å£²ä¸Šäºˆæ¸¬ã¨å®Ÿç¸¾ã®ãƒ—ãƒ­ãƒƒãƒˆé–¢æ•°
def plot_sales_prediction(df, sku_id, days=30):
    # é¸æŠã—ãŸå•†å“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    sku_data = df[df['Item_name'] == sku_id].copy()
    
    # äºˆæ¸¬å€¤ãŒã‚ã‚‹è¡Œã®ã¿ã‚’æŠ½å‡º
    sku_data = sku_data.dropna(subset=['Prediction'])
    
    # æœ€æ–°ã®æ—¥ä»˜ã‹ã‚‰æŒ‡å®šæ—¥æ•°åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    latest_data = sku_data.sort_values('Date', ascending=False).head(days)
    plot_data = latest_data.sort_values('Date')
    
    # ãƒ—ãƒ­ãƒƒãƒˆ
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=plot_data['Date'], 
        y=plot_data['Sales'],
        mode='lines+markers',
        name='å®Ÿç¸¾',
        line=dict(color='blue')
    ))
    fig.add_trace(go.Scatter(
        x=plot_data['Date'], 
        y=plot_data['Prediction'],
        mode='lines+markers',
        name='äºˆæ¸¬',
        line=dict(color='red')
    ))
    
    fig.update_layout(
        title='æ—¥æ¬¡å£²ä¸Šé«˜: å®Ÿç¸¾ vs äºˆæ¸¬ï¼ˆæœ€æ–°{}æ—¥åˆ†ï¼‰'.format(days),
        xaxis_title='æ—¥ä»˜',
        yaxis_title='å£²ä¸Šé«˜',
        legend_title='ãƒ‡ãƒ¼ã‚¿ç¨®åˆ¥',
        height=500
    )
    
    return fig

# ç‰¹å¾´é‡ã®éƒ¨åˆ†ä¾å­˜ãƒ—ãƒ­ãƒƒãƒˆ
def plot_partial_dependence(df, sku_id, feature):
    # é¸æŠã—ãŸå•†å“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    sku_data = df[df['Item_name'] == sku_id].copy()
    
    # ç‰¹å¾´é‡ã®å€¤ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦å¹³å‡å£²ä¸Šã‚’è¨ˆç®—
    if feature in sku_data.columns:
        # æ•°å€¤å‹ã®å ´åˆã¯ãƒ“ãƒ³åˆ†å‰²
        if np.issubdtype(sku_data[feature].dtype, np.number):
            # ãƒ“ãƒ³åˆ†å‰²ï¼ˆ10åˆ†ä½ï¼‰
            sku_data['bin'] = pd.qcut(sku_data[feature], 10, duplicates='drop')
            grouped = sku_data.groupby('bin')['Sales'].mean().reset_index()
            # ãƒ“ãƒ³ã®ä¸­å¤®å€¤ã‚’å–å¾—
            grouped['bin_mid'] = grouped['bin'].apply(lambda x: x.mid)
            
            # ãƒ—ãƒ­ãƒƒãƒˆ
            fig = px.line(
                grouped, 
                x='bin_mid', 
                y='Sales',
                markers=True,
                title=f'ç‰¹å¾´é‡ã®éƒ¨åˆ†ä¾å­˜: {feature}',
                labels={'bin_mid': feature, 'Sales': 'å¹³å‡å£²ä¸Š'}
            )
        else:
            # ã‚«ãƒ†ã‚´ãƒªå‹ã®å ´åˆã¯ãã®ã¾ã¾ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
            grouped = sku_data.groupby(feature)['Sales'].mean().reset_index()
            
            # ãƒ—ãƒ­ãƒƒãƒˆ
            fig = px.bar(
                grouped, 
                x=feature, 
                y='Sales',
                title=f'ç‰¹å¾´é‡ã®éƒ¨åˆ†ä¾å­˜: {feature}',
                labels={feature: feature, 'Sales': 'å¹³å‡å£²ä¸Š'}
            )
    else:
        # ç‰¹å¾´é‡ãŒãªã„å ´åˆã¯ãƒ€ãƒŸãƒ¼ã®ã‚°ãƒ©ãƒ•ã‚’è¿”ã™
        fig = go.Figure()
        fig.update_layout(
            title=f'ç‰¹å¾´é‡ã®éƒ¨åˆ†ä¾å­˜: {feature} (ãƒ‡ãƒ¼ã‚¿ãªã—)',
            xaxis_title=feature,
            yaxis_title='å¹³å‡å£²ä¸Š'
        )
    
    return fig

# éœ€è¦å¤‰å‹•è¦å› ã®å††ã‚°ãƒ©ãƒ•é–¢æ•°
def plot_demand_factors(df, sku_id):
    # é¸æŠã—ãŸå•†å“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    sku_data = df[df['Item_name'] == sku_id].copy()
    
    # ç‰¹å¾´é‡ã®åˆ—åã‚’å–å¾—
    feature_cols = [
        'Price', 'coupon_rate', 'holiday', 'tempreture',
        'precipitation', 'Sales_lag_1', 'Sales_lag_7', 'CPI',
        'Closed_flag', 'market_flag'
    ]
    
    # ç‰¹å¾´é‡ã®é‡è¦åº¦ã‚’è¨ˆç®—ï¼ˆç›¸é–¢ä¿‚æ•°ã®çµ¶å¯¾å€¤ã‚’ä½¿ç”¨ï¼‰
    factors = {}
    for col in feature_cols:
        if col in sku_data.columns:
            # NaNã‚’é™¤å¤–ã—ã¦ç›¸é–¢ä¿‚æ•°ã‚’è¨ˆç®—
            corr = sku_data[['Sales', col]].dropna().corr().iloc[0, 1]
            factors[col] = abs(corr)
        else:
            factors[col] = 0
    
    # ç‰¹å¾´é‡åã‚’æ—¥æœ¬èªã«å¤‰æ›
    feature_names_ja = {
        'Price': 'ä¾¡æ ¼',
        'coupon_rate': 'ã‚¯ãƒ¼ãƒãƒ³ç‡',
        'holiday': 'ä¼‘æ—¥',
        'tempreture': 'æ°—æ¸©',
        'precipitation': 'é™æ°´é‡',
        'Sales_lag_1': 'å‰æ—¥å£²ä¸Š',
        'Sales_lag_7': 'å‰é€±å£²ä¸Š',
        'CPI': 'æ¶ˆè²»è€…ç‰©ä¾¡æŒ‡æ•°',
        'Closed_flag': 'ä¼‘æ¥­ãƒ•ãƒ©ã‚°',
        'market_flag': 'å¸‚å ´ãƒ•ãƒ©ã‚°'
    }
    
    # æ—¥æœ¬èªåã«å¤‰æ›
    factors_ja = {feature_names_ja.get(k, k): v for k, v in factors.items()}
    
    # åˆè¨ˆãŒ100%ã«ãªã‚‹ã‚ˆã†ã«æ­£è¦åŒ–
    total = sum(factors_ja.values())
    if total > 0:
        factors_ja = {k: v/total*100 for k, v in factors_ja.items()}
    
    fig = px.pie(
        values=list(factors_ja.values()),
        names=list(factors_ja.keys()),
        title='éœ€è¦å¤‰å‹•è¦å› ã®å†…è¨³',
        hole=0.3
    )
    
    return fig

# äº¤äº’ä½œç”¨åŠ¹æœã®è¨ˆç®—ã¨å¯è¦–åŒ–
def calculate_interactions(df, sku_id):
    # é¸æŠã—ãŸå•†å“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    sku_data = df[df['Item_name'] == sku_id].copy()
    
    # ç‰¹å¾´é‡ã®åˆ—åã‚’å–å¾—
    feature_cols = [
        'Price', 'coupon_rate', 'holiday', 'tempreture',
        'precipitation', 'Sales_lag_1', 'Sales_lag_7', 'CPI',
        'Closed_flag', 'market_flag'
    ]
    
    # å­˜åœ¨ã™ã‚‹ç‰¹å¾´é‡ã®ã¿ã‚’ä½¿ç”¨
    available_features = [col for col in feature_cols if col in sku_data.columns]
    
    # äº¤äº’ä½œç”¨ã®è¨ˆç®—
    interactions = []
    
    for i in range(len(available_features)):
        for j in range(i+1, len(available_features)):
            feat1 = available_features[i]
            feat2 = available_features[j]
            
            # ä¸¡æ–¹ã®ç‰¹å¾´é‡ã§NaNãŒãªã„è¡Œã®ã¿ã‚’ä½¿ç”¨
            valid_data = sku_data.dropna(subset=[feat1, feat2, 'Sales'])
            
            if len(valid_data) > 10:  # ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿
                # ç‰¹å¾´é‡ã‚’2å€¤åŒ–ï¼ˆä¸­å¤®å€¤ã§åˆ†å‰²ï¼‰
                valid_data[f'{feat1}_high'] = valid_data[feat1] > valid_data[feat1].median()
                valid_data[f'{feat2}_high'] = valid_data[feat2] > valid_data[feat2].median()
                
                # 4ã¤ã®ã‚°ãƒ«ãƒ¼ãƒ—ã®å¹³å‡å£²ä¸Šã‚’è¨ˆç®—
                g1 = valid_data[(~valid_data[f'{feat1}_high']) & (~valid_data[f'{feat2}_high'])]['Sales'].mean()
                g2 = valid_data[(valid_data[f'{feat1}_high']) & (~valid_data[f'{feat2}_high'])]['Sales'].mean()
                g3 = valid_data[(~valid_data[f'{feat1}_high']) & (valid_data[f'{feat2}_high'])]['Sales'].mean()
                g4 = valid_data[(valid_data[f'{feat1}_high']) & (valid_data[f'{feat2}_high'])]['Sales'].mean()
                
                # äº¤äº’ä½œç”¨åŠ¹æœã®è¨ˆç®—
                # (g4 - g3) - (g2 - g1) = g4 - g3 - g2 + g1
                interaction_effect = g4 - g3 - g2 + g1
                
                # äº¤äº’ä½œç”¨åŠ¹æœã®çµ¶å¯¾å€¤ã‚’æ­£è¦åŒ–
                interactions.append({
                    'Factor1': feat1,
                    'Factor2': feat2,
                    'Effect': abs(interaction_effect)
                })
    
    # äº¤äº’ä½œç”¨åŠ¹æœã§ã‚½ãƒ¼ãƒˆ
    interactions_df = pd.DataFrame(interactions).sort_values('Effect', ascending=False)
    
    # ä¸Šä½5ã¤ã®äº¤äº’ä½œç”¨ã‚’å–å¾—
    top_interactions = interactions_df.head(5)
    
    # ç‰¹å¾´é‡åã‚’æ—¥æœ¬èªã«å¤‰æ›
    feature_names_ja = {
        'Price': 'ä¾¡æ ¼',
        'coupon_rate': 'ã‚¯ãƒ¼ãƒãƒ³ç‡',
        'holiday': 'ä¼‘æ—¥',
        'tempreture': 'æ°—æ¸©',
        'precipitation': 'é™æ°´é‡',
        'Sales_lag_1': 'å‰æ—¥å£²ä¸Š',
        'Sales_lag_7': 'å‰é€±å£²ä¸Š',
        'CPI': 'æ¶ˆè²»è€…ç‰©ä¾¡æŒ‡æ•°',
        'Closed_flag': 'ä¼‘æ¥­ãƒ•ãƒ©ã‚°',
        'market_flag': 'å¸‚å ´ãƒ•ãƒ©ã‚°'
    }
    
    # æ—¥æœ¬èªåã«å¤‰æ›
    top_interactions['Factor1_ja'] = top_interactions['Factor1'].map(lambda x: feature_names_ja.get(x, x))
    top_interactions['Factor2_ja'] = top_interactions['Factor2'].map(lambda x: feature_names_ja.get(x, x))
    
    # è¦å› ãƒšã‚¢ã®ãƒ©ãƒ™ãƒ«ã‚’ä½œæˆ
    top_interactions['Factor1 + Factor2'] = top_interactions['Factor1_ja'] + ' Ã— ' + top_interactions['Factor2_ja']
    
    # åŠ¹æœã®æœ€å¤§å€¤ã§æ­£è¦åŒ–
    if len(top_interactions) > 0 and top_interactions['Effect'].max() > 0:
        top_interactions['Effect'] = top_interactions['Effect'] / top_interactions['Effect'].max()
    
    return top_interactions

# ä¸»è¦ãªäº¤äº’ä½œç”¨åŠ¹æœã®å¯è¦–åŒ–
def plot_interactions(interactions_df):
    if len(interactions_df) == 0:
        # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ãƒ€ãƒŸãƒ¼ã®ã‚°ãƒ©ãƒ•ã‚’è¿”ã™
        fig = go.Figure()
        fig.update_layout(
            title='ä¸»è¦ãªäº¤äº’ä½œç”¨åŠ¹æœ (ãƒ‡ãƒ¼ã‚¿ãªã—)',
            xaxis_title='äº¤äº’ä½œç”¨ã®å¼·ã•',
            yaxis_title='è¦å› ãƒšã‚¢'
        )
        return fig
    
    fig = px.bar(
        interactions_df,
        x='Effect',
        y='Factor1 + Factor2',
        orientation='h',
        text='Effect',
        title='ä¸»è¦ãªäº¤äº’ä½œç”¨åŠ¹æœ',
        labels={'Effect': 'äº¤äº’ä½œç”¨ã®å¼·ã•', 'Factor1 + Factor2': 'è¦å› ãƒšã‚¢'}
    )
    
    # ã‚°ãƒ©ãƒ•ã®æ›´æ–°
    fig.update_traces(texttemplate='%{text:.2f}', textposition='outside')
    fig.update_layout(height=400)
    
    return fig

# ä¾¡æ ¼ã¨ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã®äº¤äº’ä½œç”¨ã‚°ãƒ©ãƒ•
def plot_price_marketing_interaction(df, sku_id):
    # é¸æŠã—ãŸå•†å“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    sku_data = df[df['Item_name'] == sku_id].copy()
    
    # ä¾¡æ ¼ã¨ã‚¯ãƒ¼ãƒãƒ³ç‡ã®ä¸¡æ–¹ãŒã‚ã‚‹å ´åˆ
    if 'Price' in sku_data.columns and 'coupon_rate' in sku_data.columns:
        # ä¾¡æ ¼ã‚’åˆ†é¡ï¼ˆé‡è¤‡å€¤ã‚„å°‘ãªã„ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤ã«å¯¾å¿œï¼‰
        try:
            # ã¾ãšqcutã‚’è©¦ã™ï¼ˆç­‰é »åº¦ãƒ“ãƒ³ï¼‰
            sku_data['price_level'] = pd.qcut(sku_data['Price'], 3, labels=['ä½', 'ä¸­', 'é«˜'], duplicates='drop')
        except ValueError:
            # qcutãŒå¤±æ•—ã—ãŸå ´åˆã¯cutã‚’ä½¿ç”¨ï¼ˆç­‰é–“éš”ãƒ“ãƒ³ï¼‰
            try:
                sku_data['price_level'] = pd.cut(sku_data['Price'], 3, labels=['ä½', 'ä¸­', 'é«˜'])
            except ValueError:
                # ãã‚Œã‚‚å¤±æ•—ã—ãŸå ´åˆã¯ã€ä¸­å¤®å€¤ã§2åˆ†å‰²
                median = sku_data['Price'].median()
                sku_data['price_level'] = pd.cut(
                    sku_data['Price'],
                    bins=[sku_data['Price'].min()-0.1, median, sku_data['Price'].max()+0.1],
                    labels=['ä½', 'é«˜']
                )
        
        # ã‚¯ãƒ¼ãƒãƒ³ç‡ã‚’åˆ†é¡
        # ã‚¯ãƒ¼ãƒãƒ³ç‡ãŒ0ã®å ´åˆãŒå¤šã„ãŸã‚ã€ç‰¹åˆ¥ã«å‡¦ç†
        sku_data['coupon_level'] = 'ãªã—'
        non_zero_mask = sku_data['coupon_rate'] > 0
        if non_zero_mask.sum() > 0:
            try:
                # ã¾ãšqcutã‚’è©¦ã™ï¼ˆç­‰é »åº¦ãƒ“ãƒ³ï¼‰
                sku_data.loc[non_zero_mask, 'coupon_level'] = pd.qcut(
                    sku_data.loc[non_zero_mask, 'coupon_rate'],
                    2,
                    labels=['å°è¦æ¨¡', 'å¤§è¦æ¨¡'],
                    duplicates='drop'
                )
            except ValueError:
                # qcutãŒå¤±æ•—ã—ãŸå ´åˆã¯cutã‚’ä½¿ç”¨ï¼ˆç­‰é–“éš”ãƒ“ãƒ³ï¼‰
                try:
                    sku_data.loc[non_zero_mask, 'coupon_level'] = pd.cut(
                        sku_data.loc[non_zero_mask, 'coupon_rate'],
                        2,
                        labels=['å°è¦æ¨¡', 'å¤§è¦æ¨¡']
                    )
                except ValueError:
                    # ãã‚Œã‚‚å¤±æ•—ã—ãŸå ´åˆã¯ã€ä¸­å¤®å€¤ã§2åˆ†å‰²
                    median = sku_data.loc[non_zero_mask, 'coupon_rate'].median()
                    sku_data.loc[non_zero_mask, 'coupon_level'] = pd.cut(
                        sku_data.loc[non_zero_mask, 'coupon_rate'],
                        bins=[sku_data.loc[non_zero_mask, 'coupon_rate'].min()-0.001,
                              median,
                              sku_data.loc[non_zero_mask, 'coupon_rate'].max()+0.001],
                        labels=['å°è¦æ¨¡', 'å¤§è¦æ¨¡']
                    )
        
        # ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã®å¹³å‡å£²ä¸Šã‚’è¨ˆç®—
        grouped = sku_data.groupby(['price_level', 'coupon_level'])['Sales'].mean().reset_index()
        
        # ã‚°ãƒ©ãƒ•ä½œæˆ
        fig = px.line(
            grouped, 
            x='price_level', 
            y='Sales', 
            color='coupon_level',
            markers=True,
            title='ä¾¡æ ¼ã¨ã‚¯ãƒ¼ãƒãƒ³ç‡ã®äº¤äº’ä½œç”¨åŠ¹æœ',
            labels={'price_level': 'ä¾¡æ ¼ãƒ¬ãƒ™ãƒ«', 'Sales': 'å¹³å‡å£²ä¸Š', 'coupon_level': 'ã‚¯ãƒ¼ãƒãƒ³ç‡'}
        )
    else:
        # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ãƒ€ãƒŸãƒ¼ã®ã‚°ãƒ©ãƒ•ã‚’è¿”ã™
        fig = go.Figure()
        fig.update_layout(
            title='ä¾¡æ ¼ã¨ã‚¯ãƒ¼ãƒãƒ³ç‡ã®äº¤äº’ä½œç”¨åŠ¹æœ (ãƒ‡ãƒ¼ã‚¿ãªã—)',
            xaxis_title='ä¾¡æ ¼ãƒ¬ãƒ™ãƒ«',
            yaxis_title='å¹³å‡å£²ä¸Š'
        )
    
    return fig

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°
def main():
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = load_data()
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    st.sidebar.header('è¨­å®š')
    
    # å•†å“é¸æŠ
    sku_options = sorted(df['Item_name'].unique())
    selected_sku = st.sidebar.selectbox('å•†å“ã‚’é¸æŠ', sku_options)
    
    # é¸æŠã—ãŸå•†å“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    sku_data = df[df['Item_name'] == selected_sku]
    
    # ãƒ‡ãƒ¼ã‚¿æœŸé–“ã®ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼
    date_range = st.sidebar.slider(
        'åˆ†ææœŸé–“',
        min_value=df['Date'].min().date(),
        max_value=df['Date'].max().date(),
        value=(df['Date'].min().date(), df['Date'].max().date())
    )
    
    # æ—¥ä»˜ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    filtered_data = sku_data[
        (sku_data['Date'].dt.date >= date_range[0]) & 
        (sku_data['Date'].dt.date <= date_range[1])
    ]
    
    # 1. ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ã¨è©•ä¾¡æŒ‡æ¨™ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.header('1. ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ã¨è©•ä¾¡æŒ‡æ¨™')
    
    # ãƒ‡ãƒ¼ã‚¿æ¦‚è¦è¡¨ç¤º
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # å•†å“IDã¨å•†å“åã®ãƒãƒƒãƒ”ãƒ³ã‚°
        sku_name_mapping = {
            '0': 'ã‚«ãƒƒãƒ—ãƒ©ãƒ¼ãƒ¡ãƒ³ ã—ãŠ',
            '1': 'ãƒã‚¤ãƒãƒ¥ã‚¦ ã‚°ãƒ¬ãƒ¼ãƒ—',
            '2': 'ãƒãƒ†ãƒˆãƒãƒƒãƒ—ã‚¹ ã‚³ãƒ³ã‚½ãƒ¡ãƒ‘ãƒ³ãƒ'
        }
        product_name = sku_name_mapping.get(selected_sku, selected_sku)
        st.metric('å•†å“', f"{product_name} (ID: {selected_sku})")
    
    with col2:
        st.metric('ãƒ‡ãƒ¼ã‚¿æœŸé–“', f"{filtered_data['Date'].min().date()} ã€œ {filtered_data['Date'].max().date()}")
    
    with col3:
        st.metric('ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°', len(filtered_data))
    
    # äºˆæ¸¬å€¤ãŒã‚ã‚‹è¡Œã®ã¿ã‚’æŠ½å‡ºã—ã¦è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—
    prediction_data = filtered_data.dropna(subset=['Prediction'])
    
    if len(prediction_data) > 0:
        # ãƒ¢ãƒ‡ãƒ«è©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®—
        metrics = calculate_metrics(prediction_data['Sales'].values, prediction_data['Prediction'].values)
        
        # è©•ä¾¡æŒ‡æ¨™ã®è¡¨ç¤º
        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            st.metric('RMSE', f"{metrics['RMSE']:.2f}")
        
        with col2:
            st.metric('MAE', f"{metrics['MAE']:.2f}")
        
        with col3:
            st.metric('MAPE', f"{metrics['MAPE']:.2f}%")
        
        with col4:
            st.metric('éå‰°åœ¨åº«ç‡', f"{metrics['Overstock Rate']:.2f}%")
        
        with col5:
            st.metric('æ¬ å“ç‡', f"{metrics['Stockout Rate']:.2f}%")
    else:
        st.warning("é¸æŠã—ãŸæœŸé–“ã«äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    
    # 2. æ™‚ç³»åˆ—å¯è¦–åŒ–ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.header('2. æ™‚ç³»åˆ—å¯è¦–åŒ–')
    
    col1, col2 = st.columns(2)
    
    with col1:
        # æ—¥æ¬¡å£²ä¸Šé«˜ã®å®Ÿç¸¾vsäºˆæ¸¬ã‚°ãƒ©ãƒ•
        if len(prediction_data) > 0:
            days_to_show = st.slider('è¡¨ç¤ºæ—¥æ•°', min_value=7, max_value=90, value=30)
            sales_fig = plot_sales_prediction(filtered_data, selected_sku, days=days_to_show)
            st.plotly_chart(sales_fig, use_container_width=True)
        else:
            st.info("é¸æŠã—ãŸæœŸé–“ã«äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    
    with col2:
        # ç‰¹å¾´é‡é‡è¦åº¦ã®ã‚°ãƒ©ãƒ•
        feature_importance = get_feature_importance(filtered_data, selected_sku)
        fig_importance = px.bar(
            feature_importance,
            x='Importance',
            y='Feature',
            orientation='h',
            title='ç‰¹å¾´é‡é‡è¦åº¦',
            labels={'Importance': 'é‡è¦åº¦', 'Feature': 'ç‰¹å¾´é‡'}
        )
        st.plotly_chart(fig_importance, use_container_width=True)
    
    # ç‰¹å¾´é‡ã®éƒ¨åˆ†ä¾å­˜ï¼ˆé‡è¦åº¦ãŒé«˜ã„ç‰¹å¾´é‡3ã¤ï¼‰
    st.subheader('ç‰¹å¾´é‡ã®éƒ¨åˆ†ä¾å­˜ï¼ˆé‡è¦åº¦ãŒé«˜ã„ç‰¹å¾´é‡3ã¤ï¼‰')
    
    # ä¸Šä½3ã¤ã®ç‰¹å¾´é‡ã‚’å–å¾—
    top_features = feature_importance.head(3)['Feature'].tolist()
    
    # 3ã¤ã®åˆ—ã«åˆ†ã‘ã¦è¡¨ç¤º
    cols = st.columns(3)
    
    for i, feature in enumerate(top_features):
        with cols[i]:
            pdp_fig = plot_partial_dependence(filtered_data, selected_sku, feature)
            st.plotly_chart(pdp_fig, use_container_width=True)
    
    # 3. éœ€è¦è¦å› åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.header('3. éœ€è¦è¦å› åˆ†æ')
    
    col1, col2 = st.columns(2)
    
    with col1:
        # éœ€è¦å¤‰å‹•è¦å› ã®å††ã‚°ãƒ©ãƒ•
        demand_factors_fig = plot_demand_factors(filtered_data, selected_sku)
        st.plotly_chart(demand_factors_fig, use_container_width=True)
    
    with col2:
        # ä¾¡æ ¼ã¨ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã®äº¤äº’ä½œç”¨ãƒ©ã‚¤ãƒ³ã‚°ãƒ©ãƒ•
        price_marketing_fig = plot_price_marketing_interaction(filtered_data, selected_sku)
        st.plotly_chart(price_marketing_fig, use_container_width=True)
    
    # 4. äº¤äº’ä½œç”¨åŠ¹æœã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.header('4. äº¤äº’ä½œç”¨åŠ¹æœ')
    
    # äº¤äº’ä½œç”¨åŠ¹æœã®è¨ˆç®—
    interactions_df = calculate_interactions(filtered_data, selected_sku)
    
    # ä¸»è¦ãªäº¤äº’ä½œç”¨åŠ¹æœã®è¦–è¦šåŒ–
    interactions_fig = plot_interactions(interactions_df)
    st.plotly_chart(interactions_fig, use_container_width=True)
    
    # äº¤äº’ä½œç”¨ã®è§£é‡ˆ
    if len(interactions_df) > 0:
        st.subheader('äº¤äº’ä½œç”¨åŠ¹æœã®è§£é‡ˆ')
        
        # ä¸Šä½3ã¤ã®äº¤äº’ä½œç”¨ã«ã¤ã„ã¦è§£é‡ˆã‚’è¡¨ç¤º
        for i, row in interactions_df.head(3).iterrows():
            st.write(f"- **{row['Factor1 + Factor2']}**: ã“ã‚Œã‚‰ã®è¦å› ãŒçµ„ã¿åˆã‚ã•ã‚‹ã¨ã€å˜ç‹¬ã®åŠ¹æœã‚ˆã‚Šã‚‚å¤§ããªå½±éŸ¿ãŒå£²ä¸Šã«ç¾ã‚Œã¾ã™ã€‚")
    
    # 5. ç•°å¸¸æ¤œå‡ºã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.header('5. ç•°å¸¸æ¤œå‡º')
    
    if len(prediction_data) > 0:
        # ç•°å¸¸å€¤ã®æ¤œå‡º
        anomalies = detect_anomalies(prediction_data['Sales'], prediction_data['Prediction'])
        anomaly_data = prediction_data[anomalies].copy()
        
        # ç•°å¸¸å€¤ãƒ†ãƒ¼ãƒ–ãƒ«ã®è¡¨ç¤º
        if len(anomaly_data) > 0:
            st.subheader(f'æ¤œå‡ºã•ã‚ŒãŸç•°å¸¸å€¤ ({len(anomaly_data)}ä»¶)')
            
            # è¡¨ç¤ºç”¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢
            display_data = anomaly_data.copy()
            display_data['Date'] = display_data['Date'].dt.date
            display_data['Error'] = display_data['Sales'] - display_data['Prediction']
            display_data['Error_Pct'] = (display_data['Error'] / display_data['Sales']) * 100
            
            # è¡¨ç¤ºã™ã‚‹ã‚«ãƒ©ãƒ ã‚’é¸æŠ
            columns_to_display = ['Date', 'Sales', 'Prediction', 'Error', 'Error_Pct', 'Price', 
                                'holiday', 'tempreture', 'precipitation']
            
            # å­˜åœ¨ã™ã‚‹ã‚«ãƒ©ãƒ ã®ã¿ã‚’è¡¨ç¤º
            columns_to_display = [col for col in columns_to_display if col in display_data.columns]
            
            st.dataframe(
                display_data[columns_to_display].sort_values('Date', ascending=False),
                hide_index=True,
                column_config={
                    'Date': 'æ—¥ä»˜',
                    'Sales': 'å®Ÿç¸¾å£²ä¸Š',
                    'Prediction': 'äºˆæ¸¬å£²ä¸Š',
                    'Error': 'èª¤å·®',
                    'Error_Pct': st.column_config.NumberColumn(
                        'èª¤å·®ç‡ (%)',
                        format="%.2f%%"
                    ),
                    'Price': 'ä¾¡æ ¼',
                    'holiday': 'ä¼‘æ—¥',
                    'tempreture': 'æ°—æ¸©',
                    'precipitation': 'é™æ°´é‡'
                }
            )
            
            # ç•°å¸¸å€¤ã®è¦–è¦šåŒ–
            anomaly_fig = go.Figure()
            
            # ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ
            anomaly_fig.add_trace(go.Scatter(
                x=prediction_data['Date'],
                y=prediction_data['Sales'],
                mode='lines+markers',
                name='å£²ä¸Š',
                line=dict(color='blue'),
                marker=dict(size=5)
            ))
            
            # ç•°å¸¸å€¤ã®ã¿å¼·èª¿è¡¨ç¤º
            anomaly_fig.add_trace(go.Scatter(
                x=anomaly_data['Date'],
                y=anomaly_data['Sales'],
                mode='markers',
                name='ç•°å¸¸å€¤',
                marker=dict(
                    color='red',
                    size=10,
                    symbol='x'
                )
            ))
            
            anomaly_fig.update_layout(
                title='ç•°å¸¸å€¤ã®æ™‚ç³»åˆ—è¡¨ç¤º',
                xaxis_title='æ—¥ä»˜',
                yaxis_title='å£²ä¸Šé«˜',
                height=500
            )
            
            st.plotly_chart(anomaly_fig, use_container_width=True)
        else:
            st.info('é¸æŠã—ãŸæœŸé–“å†…ã«ç•°å¸¸å€¤ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚')
    else:
        st.warning("é¸æŠã—ãŸæœŸé–“ã«äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

if __name__ == "__main__":
    main()